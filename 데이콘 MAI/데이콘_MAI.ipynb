{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "98334ba43f2d431da26430a81401092d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_de7632491d5948b58973f6dc54cbf8eb",
              "IPY_MODEL_71b040a3f0694e0d89f09373531cedc5",
              "IPY_MODEL_686a99a888144b8d954a443663e70622"
            ],
            "layout": "IPY_MODEL_26513fc2c0e44ee1a9cab34c40755c85"
          }
        },
        "de7632491d5948b58973f6dc54cbf8eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2dec57476440490ca3b24987899b03b3",
            "placeholder": "​",
            "style": "IPY_MODEL_2eb5f88b21a04da3bd98502e70f75e4b",
            "value": "Epoch 1/1: 100%"
          }
        },
        "71b040a3f0694e0d89f09373531cedc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c42ae4b17e9c436181719fb0abfec087",
            "max": 1714,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_220d4dace7524d4eb26bdce38dd65ec2",
            "value": 1714
          }
        },
        "686a99a888144b8d954a443663e70622": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f9ec37b16a8d45f191ccb4c56cade4ee",
            "placeholder": "​",
            "style": "IPY_MODEL_2f5aea781cba4cc8ab56c3966fc6fbc6",
            "value": " 1714/1714 [19:08&lt;00:00,  1.60it/s, loss=0.0100]"
          }
        },
        "26513fc2c0e44ee1a9cab34c40755c85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2dec57476440490ca3b24987899b03b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2eb5f88b21a04da3bd98502e70f75e4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c42ae4b17e9c436181719fb0abfec087": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "220d4dace7524d4eb26bdce38dd65ec2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f9ec37b16a8d45f191ccb4c56cade4ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f5aea781cba4cc8ab56c3966fc6fbc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5b7a24c83e884ea0b8cf210359f664b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d1c55da5d0d54d418414c98a0780b9fb",
              "IPY_MODEL_f199ac4866f34ebbb2ace21a9f2f059c",
              "IPY_MODEL_c212949775534be0bfc6ea4d543b5f83"
            ],
            "layout": "IPY_MODEL_0bdd127d2a1f4eb481cb47283e316b0c"
          }
        },
        "d1c55da5d0d54d418414c98a0780b9fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_19ea2e3bb48441038389410821905863",
            "placeholder": "​",
            "style": "IPY_MODEL_dfda38a6eb8643bd8b5ae3e9db849803",
            "value": "Extracting embeddings: 100%"
          }
        },
        "f199ac4866f34ebbb2ace21a9f2f059c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_795924aa74bc4af18dc14eb62112db53",
            "max": 1714,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_642ef98f6a834b04b8fadddb420a8ca0",
            "value": 1714
          }
        },
        "c212949775534be0bfc6ea4d543b5f83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ffebb1ec0591444f8cc3a8a821be32d4",
            "placeholder": "​",
            "style": "IPY_MODEL_dcf39c1952f54076a7bdda81706892a3",
            "value": " 1714/1714 [01:49&lt;00:00, 16.20it/s]"
          }
        },
        "0bdd127d2a1f4eb481cb47283e316b0c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19ea2e3bb48441038389410821905863": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dfda38a6eb8643bd8b5ae3e9db849803": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "795924aa74bc4af18dc14eb62112db53": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "642ef98f6a834b04b8fadddb420a8ca0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ffebb1ec0591444f8cc3a8a821be32d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dcf39c1952f54076a7bdda81706892a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4316724857a84646a09aecd4df32cc81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c2371eec099248efbeb96b5acd0ebd4a",
              "IPY_MODEL_b699f42c711e4cdda1d34fb65abda1b3",
              "IPY_MODEL_3b837ea4c9f74965bbc15e0a0e1cfc52"
            ],
            "layout": "IPY_MODEL_ca3d481d0c0648a7906211355205363e"
          }
        },
        "c2371eec099248efbeb96b5acd0ebd4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c879132defe141eabeaa4082d30b007d",
            "placeholder": "​",
            "style": "IPY_MODEL_b3c52e4c7c08452588788764ea8b9a88",
            "value": "Extracting embeddings: 100%"
          }
        },
        "b699f42c711e4cdda1d34fb65abda1b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a58dc49971943c1ab92b19224816b05",
            "max": 857,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_34f851007cda49e4ac0c1e22163a837b",
            "value": 857
          }
        },
        "3b837ea4c9f74965bbc15e0a0e1cfc52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2412c3431d2a449c817ca713bd3518f7",
            "placeholder": "​",
            "style": "IPY_MODEL_e5605d76bb85480883f55d86f4cee02a",
            "value": " 857/857 [1:21:21&lt;00:00,  5.67s/it]"
          }
        },
        "ca3d481d0c0648a7906211355205363e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c879132defe141eabeaa4082d30b007d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3c52e4c7c08452588788764ea8b9a88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8a58dc49971943c1ab92b19224816b05": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34f851007cda49e4ac0c1e22163a837b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2412c3431d2a449c817ca713bd3518f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5605d76bb85480883f55d86f4cee02a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b1443574c51f4765aa73bd1713f1cca9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_72ed465c15d9473586e83f388ec15436",
              "IPY_MODEL_fdd3eddea55d411cbc3327df2c9b7c2d",
              "IPY_MODEL_27989a4271584fc1a59f696e554bc871"
            ],
            "layout": "IPY_MODEL_4f88fa189a2a4776977006c257d0358e"
          }
        },
        "72ed465c15d9473586e83f388ec15436": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7981207a413a429ea74701931853b8a2",
            "placeholder": "​",
            "style": "IPY_MODEL_c125f240a7284646afdfcbad0834b40c",
            "value": "Calculating Embeddings: 100%"
          }
        },
        "fdd3eddea55d411cbc3327df2c9b7c2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_91bf1474b04a47508b03eceb8d4dd55f",
            "max": 429,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_58c4f58f1b234820b0c3d1697c4003ea",
            "value": 429
          }
        },
        "27989a4271584fc1a59f696e554bc871": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_36c801a085fc44c5844c283abc9b6098",
            "placeholder": "​",
            "style": "IPY_MODEL_d3c437e8a9da46848ef207bc19c1f8d9",
            "value": " 429/429 [02:37&lt;00:00,  3.28it/s]"
          }
        },
        "4f88fa189a2a4776977006c257d0358e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7981207a413a429ea74701931853b8a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c125f240a7284646afdfcbad0834b40c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "91bf1474b04a47508b03eceb8d4dd55f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58c4f58f1b234820b0c3d1697c4003ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "36c801a085fc44c5844c283abc9b6098": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d3c437e8a9da46848ef207bc19c1f8d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4cf8a54cf77a42de8798a6288b311b20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_50037110a26444b39ac9f4becb34856f",
              "IPY_MODEL_3ba86012cc8646e99fa209cc96711f3d",
              "IPY_MODEL_89a98d645bdd42ce955509a276ee89c8"
            ],
            "layout": "IPY_MODEL_fabb1dcb7a3c4e71a09939cff0b145b0"
          }
        },
        "50037110a26444b39ac9f4becb34856f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2f4c908433a446819ef5c62902620748",
            "placeholder": "​",
            "style": "IPY_MODEL_980e394270234c4ebc38ea393f5ec8b8",
            "value": "100%"
          }
        },
        "3ba86012cc8646e99fa209cc96711f3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b89b058229ef4ceb9843dbac045f3b0e",
            "max": 1714,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a46faa696ef04d61a587e5f03a3da045",
            "value": 1714
          }
        },
        "89a98d645bdd42ce955509a276ee89c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9390a455b94d46c5bae7c255b0b4c5ad",
            "placeholder": "​",
            "style": "IPY_MODEL_9b8da269c6e448a99ea4f0c7f9f9a6d7",
            "value": " 1714/1714 [29:31&lt;00:00,  1.02it/s]"
          }
        },
        "fabb1dcb7a3c4e71a09939cff0b145b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f4c908433a446819ef5c62902620748": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "980e394270234c4ebc38ea393f5ec8b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b89b058229ef4ceb9843dbac045f3b0e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a46faa696ef04d61a587e5f03a3da045": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9390a455b94d46c5bae7c255b0b4c5ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b8da269c6e448a99ea4f0c7f9f9a6d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7aac0cd7543f4364a21effbed75f338c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5b6888e277c84ba2ac132bcf2669fab6",
              "IPY_MODEL_2dd9fbf2f16d4910a476d06f650b596f",
              "IPY_MODEL_dc3b31dbd1494ba5aa98f588bb78acca"
            ],
            "layout": "IPY_MODEL_6250a29bed0944079fdf884658476f31"
          }
        },
        "5b6888e277c84ba2ac132bcf2669fab6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0cfa22dce8b847df8fc9375f907bd19c",
            "placeholder": "​",
            "style": "IPY_MODEL_df716426995e47b8972339e4c2bab2be",
            "value": "100%"
          }
        },
        "2dd9fbf2f16d4910a476d06f650b596f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1ad92820d0d84bdcbabd144135850008",
            "max": 1714,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_30b7217b88814e5eb6fea4858a05022a",
            "value": 1714
          }
        },
        "dc3b31dbd1494ba5aa98f588bb78acca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2fa97ba877844ddc94d08aab0604da25",
            "placeholder": "​",
            "style": "IPY_MODEL_982c0dfa8f704b5b87d222a2ffa9ae41",
            "value": " 1714/1714 [00:47&lt;00:00, 36.73it/s]"
          }
        },
        "6250a29bed0944079fdf884658476f31": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0cfa22dce8b847df8fc9375f907bd19c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df716426995e47b8972339e4c2bab2be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1ad92820d0d84bdcbabd144135850008": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30b7217b88814e5eb6fea4858a05022a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2fa97ba877844ddc94d08aab0604da25": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "982c0dfa8f704b5b87d222a2ffa9ae41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fbde6174c6ab46c985d8f565df59c82f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f8a04e92815944ebb662be23c3a3a6de",
              "IPY_MODEL_48c19b8b18524be186e45ba91e57d2b6",
              "IPY_MODEL_d99356ec23604959a57f1e53707bbecc"
            ],
            "layout": "IPY_MODEL_a7a499c7913d48f0a96ad9b3f31f42f7"
          }
        },
        "f8a04e92815944ebb662be23c3a3a6de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3421899a7edc4682b22960d7b2b420b2",
            "placeholder": "​",
            "style": "IPY_MODEL_d84e2171176a4c889d231a8961d8b819",
            "value": "Epoch 1/1: 100%"
          }
        },
        "48c19b8b18524be186e45ba91e57d2b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e7cf25cf124f4fe8b04a1ce6a548c850",
            "max": 1714,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dd93ab3a015349a5ac0e800d0cfa174c",
            "value": 1714
          }
        },
        "d99356ec23604959a57f1e53707bbecc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_524bdfa9cbe14b5b9a6e4b7682d43d63",
            "placeholder": "​",
            "style": "IPY_MODEL_6b327a73419a4c8f886c5545634b0b23",
            "value": " 1714/1714 [12:48&lt;00:00,  2.34it/s, loss=0.1432]"
          }
        },
        "a7a499c7913d48f0a96ad9b3f31f42f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3421899a7edc4682b22960d7b2b420b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d84e2171176a4c889d231a8961d8b819": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e7cf25cf124f4fe8b04a1ce6a548c850": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd93ab3a015349a5ac0e800d0cfa174c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "524bdfa9cbe14b5b9a6e4b7682d43d63": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b327a73419a4c8f886c5545634b0b23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b4d90e27214947fbad221df49dd40d27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_26262d82a1734b68b81e070d26dd88f8",
              "IPY_MODEL_ca31a04838f64178b2b02381eee1f1ff",
              "IPY_MODEL_11c26ff8d3164e6bb22193d3b1245911"
            ],
            "layout": "IPY_MODEL_1924a1aba25241078941c584de207526"
          }
        },
        "26262d82a1734b68b81e070d26dd88f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac68e748b83b4ec19484e86dccea93f7",
            "placeholder": "​",
            "style": "IPY_MODEL_057f56c1efdc4cf59200f2ddb0be03de",
            "value": "Extracting embeddings: 100%"
          }
        },
        "ca31a04838f64178b2b02381eee1f1ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a69041ee7c0747c7a962dd5d6f27bb16",
            "max": 429,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a73116b7806042d19b6209fa1c9c0ca2",
            "value": 429
          }
        },
        "11c26ff8d3164e6bb22193d3b1245911": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_06638fdf8033475ea1a8035b3a8789af",
            "placeholder": "​",
            "style": "IPY_MODEL_30c1bd79a4c245d980f7ca10750e6a0f",
            "value": " 429/429 [01:26&lt;00:00,  5.40it/s]"
          }
        },
        "1924a1aba25241078941c584de207526": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac68e748b83b4ec19484e86dccea93f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "057f56c1efdc4cf59200f2ddb0be03de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a69041ee7c0747c7a962dd5d6f27bb16": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a73116b7806042d19b6209fa1c9c0ca2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "06638fdf8033475ea1a8035b3a8789af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30c1bd79a4c245d980f7ca10750e6a0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "id": "6OClK5l4Tcvv",
        "outputId": "aa58aca4-8934-4c32-c940-66cd7173d647"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (ipython-input-984273395.py, line 1)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-984273395.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    pip install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "pip install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
        "pip install -q transformers datasets accelerate tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import math\n",
        "from typing import List, Tuple\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForMaskedLM, get_linear_schedule_with_warmup\n"
      ],
      "metadata": {
        "id": "RaIn7HfuTjXZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# 0. 설정값 (필요하면 위쪽만 수정해서 튜닝)\n",
        "# ================================\n",
        "MODEL_NAME = \"InstaDeepAI/nucleotide-transformer-v2-50m-multi-species\" #DNA 전용 언어모델 이름\n",
        "\n",
        "TEST_PATH = \"test.csv\"                  # 대회 제공 test.csv 경로\n",
        "SAMPLE_SUB_PATH = \"sample_submission.csv\"\n",
        "OUTPUT_PATH = \"submission_ntv2_contrastive.csv\"\n",
        "\n",
        "MAX_SEQ_LEN = 512                         # 토큰 최대 길이 (모델 max_length 보다 작게) #최대 몇 글자까지 볼건지\n",
        "EMBED_DIM = 512                           # hidden_size (v2-50m은 512)\n",
        "\n",
        "DO_TRAIN = True                           # 파인튜닝 할지 여부\n",
        "MAX_TRAIN_SEQS = 20000                    # test 중 학습에 쓸 최대 시퀀스 수\n",
        "EPOCHS = 1                                # Colab 기준 1~2 에폭 추천\n",
        "BATCH_SIZE = 8\n",
        "LR = 2e-5\n",
        "WARMUP_RATIO = 0.05\n",
        "\n",
        "# 돌연변이 수준 (시퀀스 길이에 대한 비율)\n",
        "MUTATION_LEVELS = [0.002, 0.005, 0.01]    # 0.2%, 0.5%, 1% SNV #DNA를 얼마나 조금 바꿀지\n",
        "BASE_MARGIN = 0.1                         # 최소 margin\n",
        "ALPHA_MARGIN = 5.0                        # 돌연변이 비율에 따라 margin 증가 정도\n",
        "\n",
        "SEED = 2025\n"
      ],
      "metadata": {
        "id": "N3TozTwsTw4M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# 1. 유틸 함수들\n",
        "# ================================\n",
        "def set_seed(seed: int = 42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "\n",
        "#DNA 일부를 조금 바꿔 모델이 이 차이를 느끼는지 훈련\n",
        "def mutate_sequence_snvs(seq: str, mutation_ratio: float) -> Tuple[str, int]:\n",
        "    \"\"\"\n",
        "    주어진 DNA 염기열에 대해 SNV(single nucleotide variants)만 랜덤으로 넣어서\n",
        "    '조금 다른' variant 시퀀스를 만든다.\n",
        "\n",
        "    return: (mutated_seq, num_mutations)\n",
        "    \"\"\"\n",
        "    bases = [\"A\", \"C\", \"G\", \"T\"]\n",
        "    seq = seq.upper()\n",
        "\n",
        "    length = len(seq)\n",
        "    num_mutations = max(1, int(length * mutation_ratio))\n",
        "\n",
        "    if num_mutations >= length:\n",
        "        num_mutations = length // 2 if length >= 2 else 1\n",
        "\n",
        "    positions = random.sample(range(length), num_mutations)\n",
        "    seq_list = list(seq)\n",
        "\n",
        "    for pos in positions:\n",
        "        original = seq_list[pos]\n",
        "        # 원래 염기 제외한 다른 염기 중 랜덤\n",
        "        candidates = [b for b in bases if b != original]\n",
        "        if not candidates:\n",
        "            continue\n",
        "        seq_list[pos] = random.choice(candidates)\n",
        "\n",
        "    mutated = \"\".join(seq_list)\n",
        "    return mutated, num_mutations\n",
        "\n",
        "\n",
        "#DNA전체를 하나의 숫자벡터로 요약\n",
        "def mean_pool(last_hidden_state: torch.Tensor, attention_mask: torch.Tensor) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    pad 토큰을 제외하고 token dimension 평균을 내서 [batch, hidden] 임베딩 생성\n",
        "    \"\"\"\n",
        "    mask = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n",
        "    masked_hidden = last_hidden_state * mask\n",
        "    summed = masked_hidden.sum(dim=1)\n",
        "    counts = mask.sum(dim=1).clamp(min=1e-6)\n",
        "    return summed / counts\n",
        "\n",
        "#두 벡터가 얼마나 다른지 점수내기: 값이 클수록 좋다\n",
        "def cosine_distance(a: torch.Tensor, b: torch.Tensor) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    코사인 거리: 1 - cos_sim\n",
        "    \"\"\"\n",
        "    return 1.0 - F.cosine_similarity(a, b)"
      ],
      "metadata": {
        "id": "mx_urO0XTytE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# 2. Dataset 정의\n",
        "# ================================\n",
        "\n",
        "#“얼마나 바뀌었는지에 따라 점수 차이를 느끼게” 학습\n",
        "class MutationContrastiveDataset(Dataset):\n",
        "    \"\"\"\n",
        "    - original seq\n",
        "    - 여러 수준의 mutated seq (SNV 비율만 다름)\n",
        "\n",
        "    한 sample에서:\n",
        "    - original embedding\n",
        "    - 각 수준별 mutated embedding 간 거리에 margin loss를 줄 예정\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, seq_list: List[str], mutation_levels: List[float]):\n",
        "        self.seqs = seq_list\n",
        "        self.mutation_levels = mutation_levels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.seqs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        seq = self.seqs[idx]\n",
        "        mutated_seqs = []\n",
        "        num_muts = []\n",
        "        for r in self.mutation_levels:\n",
        "            m_seq, n_mut = mutate_sequence_snvs(seq, r)\n",
        "            mutated_seqs.append(m_seq)\n",
        "            num_muts.append(n_mut)\n",
        "        return {\n",
        "            \"original\": seq,\n",
        "            \"mutated_list\": mutated_seqs,\n",
        "            \"num_mut_list\": num_muts,\n",
        "        }\n",
        "\n",
        "\n",
        "#DataLoader가 여러 문제를 한 묶음(batch)으로 만들 때 쓰는 함수\n",
        "'''\n",
        "DNA 문자열을 **AI가 이해하는 숫자(ID)**로 변환\n",
        "\n",
        "원본용 토큰\n",
        "\n",
        "변이 1,2,3용 토큰\n",
        "\n",
        "“몇 글자 바뀌었는지” 텐서로 만듦\n",
        "'''\n",
        "def collate_fn(batch, tokenizer, max_len: int):\n",
        "    originals = [b[\"original\"] for b in batch]\n",
        "    mutated_lists = [b[\"mutated_list\"] for b in batch]\n",
        "    num_mut_lists = [b[\"num_mut_list\"] for b in batch]\n",
        "\n",
        "    # 원본 토큰화\n",
        "    orig_enc = tokenizer(\n",
        "        originals,\n",
        "        padding=True,\n",
        "        truncation=True,\n",
        "        max_length=max_len,\n",
        "        return_tensors=\"pt\",\n",
        "    )\n",
        "\n",
        "    # mutation level 별로 토큰화 (각 level에 대해 배치 전체)\n",
        "    # mutated_tokenized[level_idx][\"input_ids\"].shape == [B, L]\n",
        "    mutated_tokenized = []\n",
        "    num_levels = len(mutated_lists[0])\n",
        "\n",
        "    for level_idx in range(num_levels):\n",
        "        seqs_level = [mutated_lists[i][level_idx] for i in range(len(batch))]\n",
        "        enc = tokenizer(\n",
        "            seqs_level,\n",
        "            padding=True,\n",
        "            truncation=True,\n",
        "            max_length=max_len,\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "        mutated_tokenized.append(enc)\n",
        "\n",
        "    num_mut_tensor = torch.tensor(num_mut_lists, dtype=torch.float32)  # [B, num_levels]\n",
        "\n",
        "    return orig_enc, mutated_tokenized, num_mut_tensor\n"
      ],
      "metadata": {
        "id": "JFZkaDCLT1HD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# 3. 모델 로드\n",
        "# ================================\n",
        "def load_glm_model(model_name: str, device: torch.device):\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
        "    model = AutoModelForMaskedLM.from_pretrained(model_name, trust_remote_code=True)\n",
        "    model.to(device)\n",
        "\n",
        "    return tokenizer, model"
      ],
      "metadata": {
        "id": "0KeLKPOQT3pM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# 4. 파인튜닝 루프\n",
        "# ================================\n",
        "\n",
        "#1.원본 DNA 임베딩 만들기, 2.돌연변이 DNA 임베딩 만들기, 3.거리 계산\n",
        "def train_variant_sensitive_glm(\n",
        "    model,\n",
        "    tokenizer,\n",
        "    train_seqs: List[str],\n",
        "    device: torch.device,\n",
        "):\n",
        "    dataset = MutationContrastiveDataset(train_seqs, MUTATION_LEVELS)\n",
        "    dataloader = DataLoader(\n",
        "        dataset,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=True,\n",
        "        collate_fn=lambda batch: collate_fn(batch, tokenizer, MAX_SEQ_LEN),\n",
        "    )\n",
        "\n",
        "    num_training_steps = EPOCHS * len(dataloader)\n",
        "    warmup_steps = int(num_training_steps * WARMUP_RATIO)\n",
        "\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=LR)\n",
        "    scheduler = get_linear_schedule_with_warmup(\n",
        "        optimizer,\n",
        "        num_warmup_steps=warmup_steps,\n",
        "        num_training_steps=num_training_steps,\n",
        "    )\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for epoch in range(EPOCHS):\n",
        "        epoch_loss = 0.0\n",
        "        progress_bar = tqdm(dataloader, desc=f\"Epoch {epoch+1}/{EPOCHS}\")\n",
        "\n",
        "        for step, (orig_enc, mutated_tokenized, num_mut_tensor) in enumerate(progress_bar):\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "             # 이 줄 추가!!!\n",
        "            num_mut_tensor = num_mut_tensor.to(device)\n",
        "\n",
        "            orig_input_ids = orig_enc[\"input_ids\"].to(device)\n",
        "            orig_attn_mask = orig_enc[\"attention_mask\"].to(device)\n",
        "\n",
        "            # 원본 시퀀스 임베딩\n",
        "            outputs_orig = model(\n",
        "                input_ids=orig_input_ids,\n",
        "                attention_mask=orig_attn_mask,\n",
        "                output_hidden_states=True,\n",
        "            )\n",
        "            last_hidden_orig = outputs_orig.hidden_states[-1]  # [B, L, H]\n",
        "            emb_orig = mean_pool(last_hidden_orig, orig_attn_mask)  # [B, H] #원본 DNA 임베딩 만들기\n",
        "\n",
        "            # mutation level 별 임베딩 및 loss 계산\n",
        "            batch_size = orig_input_ids.size(0)\n",
        "            num_levels = len(mutated_tokenized)\n",
        "\n",
        "            loss_all_levels = 0.0\n",
        "\n",
        "            # mutation 수 (정수)를 비율로 바꿔 margin 설계\n",
        "            seq_len_est = orig_attn_mask.sum(dim=1, keepdim=True)  # [B, 1]\n",
        "            mut_ratio = num_mut_tensor / seq_len_est  # [B, num_levels]\n",
        "\n",
        "            for level_idx in range(num_levels):\n",
        "                enc_level = mutated_tokenized[level_idx]\n",
        "                m_input_ids = enc_level[\"input_ids\"].to(device)\n",
        "                m_attn_mask = enc_level[\"attention_mask\"].to(device)\n",
        "\n",
        "                outputs_mut = model(\n",
        "                    input_ids=m_input_ids,\n",
        "                    attention_mask=m_attn_mask,\n",
        "                    output_hidden_states=True,\n",
        "                )\n",
        "                last_hidden_mut = outputs_mut.hidden_states[-1]\n",
        "                emb_mut = mean_pool(last_hidden_mut, m_attn_mask)  # [B, H] #돌연변이 임베딩 DNA 만들기\n",
        "\n",
        "                dist = cosine_distance(emb_orig, emb_mut)  # [B] #거리  계산\n",
        "\n",
        "                # margin: BASE_MARGIN + ALPHA * mutation_ratio\n",
        "                margin = BASE_MARGIN + ALPHA_MARGIN * mut_ratio[:, level_idx] #DNA를 많이 바꾸면 점수 차이도 더 커야한\n",
        "                margin = margin.to(device)\n",
        "\n",
        "                # hinge loss: dist >= margin\n",
        "                loss_level = F.relu(margin - dist).mean()\n",
        "                loss_all_levels = loss_all_levels + loss_level\n",
        "\n",
        "            loss = loss_all_levels / num_levels\n",
        "            loss.backward()\n",
        "\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            progress_bar.set_postfix({\"loss\": f\"{loss.item():.4f}\"})\n",
        "\n",
        "        print(f\"[Epoch {epoch+1}] mean loss = {epoch_loss / len(dataloader):.4f}\")\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "nxE3JP3qT5uJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# 5. test.csv 전체 임베딩 추출\n",
        "# ================================\n",
        "class TestSeqDataset(Dataset):\n",
        "    def __init__(self, df: pd.DataFrame):\n",
        "        self.ids = df[\"ID\"].tolist()\n",
        "        self.seqs = df[\"seq\"].astype(str).tolist()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.ids[idx], self.seqs[idx]\n",
        "\n",
        "\n",
        "def collate_test(batch, tokenizer, max_len: int):\n",
        "    ids = [b[0] for b in batch]\n",
        "    seqs = [b[1] for b in batch]\n",
        "    enc = tokenizer(\n",
        "        seqs,\n",
        "        padding=True,\n",
        "        truncation=True,\n",
        "        max_length=max_len,\n",
        "        return_tensors=\"pt\",\n",
        "    )\n",
        "    return ids, enc\n",
        "\n",
        "\n",
        "def extract_embeddings( #학습 끝난 모델로 벡터화시켜 반환\n",
        "    model,\n",
        "    tokenizer,\n",
        "    test_df: pd.DataFrame,\n",
        "    device: torch.device,\n",
        ") -> pd.DataFrame:\n",
        "    model.eval()\n",
        "    dataset = TestSeqDataset(test_df)\n",
        "    dataloader = DataLoader(\n",
        "        dataset,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=False,\n",
        "        collate_fn=lambda batch: collate_test(batch, tokenizer, MAX_SEQ_LEN),\n",
        "    )\n",
        "\n",
        "    all_ids = []\n",
        "    all_embs = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for ids, enc in tqdm(dataloader, desc=\"Extracting embeddings\"):\n",
        "            input_ids = enc[\"input_ids\"].to(device)\n",
        "            attn_mask = enc[\"attention_mask\"].to(device)\n",
        "\n",
        "            outputs = model(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attn_mask,\n",
        "                output_hidden_states=True,\n",
        "            )\n",
        "            last_hidden = outputs.hidden_states[-1]\n",
        "            emb = mean_pool(last_hidden, attn_mask)  # [B, H]\n",
        "\n",
        "            emb = emb.detach().cpu().numpy()\n",
        "            all_ids.extend(ids)\n",
        "            all_embs.append(emb)\n",
        "\n",
        "    all_embs = np.vstack(all_embs)  # [N, EMBED_DIM]\n",
        "\n",
        "    # submission 포맷으로 변환\n",
        "    # sample_submission.csv의 ID 순서에 맞춰서 정렬\n",
        "    sub = pd.read_csv(SAMPLE_SUB_PATH)\n",
        "    id_to_index = {id_: i for i, id_ in enumerate(all_ids)}\n",
        "    ordered_embs = np.zeros((len(sub), EMBED_DIM), dtype=np.float32)\n",
        "\n",
        "    for i, id_ in enumerate(sub[\"ID\"].tolist()):\n",
        "        idx = id_to_index[id_]\n",
        "        ordered_embs[i] = all_embs[idx]\n",
        "\n",
        "    emb_cols = [f\"emb_{i:04d}\" for i in range(EMBED_DIM)]\n",
        "    emb_df = pd.DataFrame(ordered_embs, columns=emb_cols)\n",
        "    out_df = pd.concat([sub[[\"ID\"]], emb_df], axis=1)\n",
        "\n",
        "    return out_df\n"
      ],
      "metadata": {
        "id": "Tqya5JmCT8t0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# 6. 메인 실행부\n",
        "# ================================\n",
        "def main():\n",
        "    set_seed(SEED)\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(\"Device:\", device)\n",
        "\n",
        "    # 데이터 로드\n",
        "    test_df = pd.read_csv(TEST_PATH)\n",
        "    print(\"test shape:\", test_df.shape)\n",
        "\n",
        "    # gLM 로드\n",
        "    tokenizer, model = load_glm_model(MODEL_NAME, device)\n",
        "\n",
        "    # ---------- 파인튜닝 ----------\n",
        "    if DO_TRAIN:\n",
        "        # 너무 크면 일부 샘플만 사용 (시간 절약용)\n",
        "        uniq_seqs = test_df[\"seq\"].astype(str).unique().tolist()\n",
        "        random.shuffle(uniq_seqs)\n",
        "        if len(uniq_seqs) > MAX_TRAIN_SEQS:\n",
        "            train_seqs = uniq_seqs[:MAX_TRAIN_SEQS]\n",
        "        else:\n",
        "            train_seqs = uniq_seqs\n",
        "\n",
        "        print(f\"Train sequences: {len(train_seqs)}\")\n",
        "        model = train_variant_sensitive_glm(\n",
        "            model=model,\n",
        "            tokenizer=tokenizer,\n",
        "            train_seqs=train_seqs,\n",
        "            device=device,\n",
        "        )\n",
        "\n",
        "    # ---------- 임베딩 추출 ----------\n",
        "    submission_df = extract_embeddings(\n",
        "        model=model,\n",
        "        tokenizer=tokenizer,\n",
        "        test_df=test_df,\n",
        "        device=device,\n",
        "    )\n",
        "\n",
        "    # 저장\n",
        "    submission_df.to_csv(OUTPUT_PATH, index=False)\n",
        "    print(\"Saved submission to:\", OUTPUT_PATH)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173,
          "referenced_widgets": [
            "98334ba43f2d431da26430a81401092d",
            "de7632491d5948b58973f6dc54cbf8eb",
            "71b040a3f0694e0d89f09373531cedc5",
            "686a99a888144b8d954a443663e70622",
            "26513fc2c0e44ee1a9cab34c40755c85",
            "2dec57476440490ca3b24987899b03b3",
            "2eb5f88b21a04da3bd98502e70f75e4b",
            "c42ae4b17e9c436181719fb0abfec087",
            "220d4dace7524d4eb26bdce38dd65ec2",
            "f9ec37b16a8d45f191ccb4c56cade4ee",
            "2f5aea781cba4cc8ab56c3966fc6fbc6",
            "5b7a24c83e884ea0b8cf210359f664b2",
            "d1c55da5d0d54d418414c98a0780b9fb",
            "f199ac4866f34ebbb2ace21a9f2f059c",
            "c212949775534be0bfc6ea4d543b5f83",
            "0bdd127d2a1f4eb481cb47283e316b0c",
            "19ea2e3bb48441038389410821905863",
            "dfda38a6eb8643bd8b5ae3e9db849803",
            "795924aa74bc4af18dc14eb62112db53",
            "642ef98f6a834b04b8fadddb420a8ca0",
            "ffebb1ec0591444f8cc3a8a821be32d4",
            "dcf39c1952f54076a7bdda81706892a3"
          ]
        },
        "id": "a_Zkpwg6UAhk",
        "outputId": "5258d875-a570-46de-ce02-3559511a1397"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n",
            "test shape: (13711, 2)\n",
            "Train sequences: 13711\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch 1/1:   0%|          | 0/1714 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "98334ba43f2d431da26430a81401092d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 1] mean loss = 0.0651\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Extracting embeddings:   0%|          | 0/1714 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5b7a24c83e884ea0b8cf210359f664b2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved submission to: submission_ntv2_contrastive.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#코드 개선"
      ],
      "metadata": {
        "id": "SJyEYCLFixqr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import math\n",
        "from typing import List, Tuple\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModel, get_cosine_schedule_with_warmup\n"
      ],
      "metadata": {
        "id": "RMLgx6OCjxdK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# 0. 설정값\n",
        "# ================================\n",
        "MODEL_NAME = \"InstaDeepAI/nucleotide-transformer-v2-50m-multi-species\"\n",
        "\n",
        "TEST_PATH = \"test.csv\"\n",
        "SAMPLE_SUB_PATH = \"sample_submission.csv\"\n",
        "OUTPUT_PATH = \"submission_v2_fixed.csv\"\n",
        "\n",
        "MAX_SEQ_LEN = 512\n",
        "EMBED_DIM = 512   # 최종 embedding dimension\n",
        "\n",
        "DO_TRAIN = True\n",
        "MAX_TRAIN_SEQS = 20000\n",
        "EPOCHS = 1\n",
        "BATCH_SIZE = 8\n",
        "LR = 2e-5\n",
        "WARMUP_RATIO = 0.05\n",
        "\n",
        "MUTATION_LEVELS = [0.002, 0.005, 0.01]\n",
        "BASE_MARGIN = 0.1\n",
        "ALPHA_MARGIN = 5.0\n",
        "\n",
        "SEED = 2025\n",
        "\n"
      ],
      "metadata": {
        "id": "3hidJYBojyGS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# 1. 유틸\n",
        "# ================================\n",
        "def set_seed(seed: int = 42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "\n",
        "# ---- Center Crop ----\n",
        "def center_crop(seq, max_len):\n",
        "    if len(seq) <= max_len:\n",
        "        return seq\n",
        "    start = (len(seq) - max_len) // 2\n",
        "    return seq[start:start + max_len]\n",
        "\n",
        "\n",
        "# ---- Reverse Complement ----\n",
        "def reverse_complement(seq):\n",
        "    comp = {\"A\": \"T\", \"T\": \"A\", \"C\": \"G\", \"G\": \"C\"}\n",
        "    return \"\".join(comp.get(b, b) for b in reversed(seq))\n",
        "\n",
        "\n",
        "# ---- SNV ----\n",
        "def mutate_snvs(seq: str, mutation_ratio: float) -> Tuple[str, int]:\n",
        "    bases = [\"A\", \"C\", \"G\", \"T\"]\n",
        "    seq = seq.upper()\n",
        "    length = len(seq)\n",
        "    num_mut = max(1, int(length * mutation_ratio))\n",
        "\n",
        "    positions = random.sample(range(length), num_mut)\n",
        "    seq_list = list(seq)\n",
        "\n",
        "    for pos in positions:\n",
        "        orig = seq_list[pos]\n",
        "        candidates = [b for b in bases if b != orig]\n",
        "        seq_list[pos] = random.choice(candidates)\n",
        "\n",
        "    return \"\".join(seq_list), num_mut\n",
        "\n",
        "\n",
        "# ---- Deletion ----\n",
        "def mutate_delete(seq: str, ratio: float):\n",
        "    seq = list(seq)\n",
        "    k = max(1, int(len(seq) * ratio))\n",
        "    for _ in range(k):\n",
        "        if len(seq) <= 1: break\n",
        "        pos = random.randrange(len(seq))\n",
        "        del seq[pos]\n",
        "    return \"\".join(seq)\n",
        "\n",
        "\n",
        "# ---- Insertion ----\n",
        "def mutate_insert(seq: str, ratio: float):\n",
        "    bases = [\"A\", \"C\", \"G\", \"T\"]\n",
        "    seq = list(seq)\n",
        "    k = max(1, int(len(seq) * ratio))\n",
        "    for _ in range(k):\n",
        "        pos = random.randrange(len(seq))\n",
        "        seq.insert(pos, random.choice(bases))\n",
        "    return \"\".join(seq)\n",
        "\n",
        "\n",
        "# ---- Advanced Pooling: mean + max concat ----\n",
        "def advanced_pool(last_hidden, attention_mask):\n",
        "    mask = attention_mask.unsqueeze(-1).expand(last_hidden.size()).float()\n",
        "    hidden = last_hidden * mask\n",
        "\n",
        "    mean = hidden.sum(dim=1) / mask.sum(dim=1).clamp(min=1e-6)\n",
        "    max_ = hidden.masked_fill(mask == 0, -1e9).max(dim=1).values\n",
        "\n",
        "    return torch.cat([mean, max_], dim=1)   # [B, hidden*2]\n",
        "\n",
        "\n",
        "# ---- Cosine distance ----\n",
        "def cosine_distance(a: torch.Tensor, b: torch.Tensor) -> torch.Tensor:\n",
        "    return 1.0 - F.cosine_similarity(a, b)\n",
        "\n"
      ],
      "metadata": {
        "id": "qzgowV4Ij1Cz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# 2. Dataset\n",
        "# ================================\n",
        "class MutationContrastiveDataset(Dataset):\n",
        "    def __init__(self, seq_list: List[str], mutation_levels: List[float]):\n",
        "        self.seqs = seq_list\n",
        "        self.mutation_levels = mutation_levels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.seqs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        seq = center_crop(self.seqs[idx], MAX_SEQ_LEN)\n",
        "\n",
        "        mutated = []\n",
        "        mut_counts = []\n",
        "\n",
        "        for r in self.mutation_levels:\n",
        "            m1, c1 = mutate_snvs(seq, r)\n",
        "            m2 = mutate_delete(seq, r)\n",
        "            m3 = mutate_insert(seq, r)\n",
        "            m4 = reverse_complement(seq)\n",
        "\n",
        "            mutated.append([m1, m2, m3, m4])\n",
        "            mut_counts.append([c1, len(seq)*r, len(seq)*r, len(seq)])\n",
        "\n",
        "        return {\"orig\": seq, \"mut\": mutated, \"mut_count\": mut_counts}\n",
        "\n",
        "\n",
        "def collate_fn(batch, tokenizer):\n",
        "    origs = [b[\"orig\"] for b in batch]\n",
        "    orig_enc = tokenizer(\n",
        "        origs,\n",
        "        padding=True,\n",
        "        truncation=True,\n",
        "        max_length=MAX_SEQ_LEN,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "\n",
        "    mutated = [b[\"mut\"] for b in batch]      # shape: B × L × A\n",
        "    mut_counts = torch.tensor([b[\"mut_count\"] for b in batch], dtype=torch.float32)\n",
        "\n",
        "    B = len(batch)\n",
        "    L = len(mutated[0])\n",
        "    A = len(mutated[0][0])\n",
        "\n",
        "    mut_token = [[None for _ in range(A)] for _ in range(L)]\n",
        "\n",
        "    for i in range(L):\n",
        "        for j in range(A):\n",
        "            seqs = [mutated[b][i][j] for b in range(B)]\n",
        "            enc = tokenizer(\n",
        "                seqs,\n",
        "                padding=True,\n",
        "                truncation=True,\n",
        "                max_length=MAX_SEQ_LEN,\n",
        "                return_tensors=\"pt\"\n",
        "            )\n",
        "            mut_token[i][j] = enc\n",
        "\n",
        "    return orig_enc, mut_token, mut_counts\n"
      ],
      "metadata": {
        "id": "Jp0XXZQ2j3ZC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# 3. Model Loader (Backbone + External Projection Head)\n",
        "# ================================\n",
        "def load_glm_model(model_name, device):\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\n",
        "        model_name, trust_remote_code=True\n",
        "    )\n",
        "\n",
        "    # ✔ backbone만 로드 → state_dict 충돌 없음\n",
        "    backbone = AutoModel.from_pretrained(\n",
        "    model_name,\n",
        "    trust_remote_code=True,\n",
        "    ignore_mismatched_sizes=True\n",
        ").to(device)\n",
        "\n",
        "    hidden = backbone.config.hidden_size      # v2-50M: 768\n",
        "\n",
        "    proj_head = nn.Sequential(\n",
        "        nn.Linear(hidden * 2, 512),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(512, 512)\n",
        "    ).to(device)\n",
        "\n",
        "    return tokenizer, backbone, proj_head\n",
        "\n",
        "\n",
        "# ---- Forward Embedding ----\n",
        "def forward_embedding(backbone, proj_head, input_ids, attn_mask):\n",
        "    out = backbone(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attn_mask,\n",
        "        output_hidden_states=True,\n",
        "    )\n",
        "    last_hidden = out.hidden_states[-1]\n",
        "\n",
        "    pooled = advanced_pool(last_hidden, attn_mask)\n",
        "    emb = proj_head(pooled)\n",
        "    emb = F.normalize(emb, dim=1)\n",
        "\n",
        "    return emb\n"
      ],
      "metadata": {
        "id": "7k3nWV_hj7Pa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# 4. Training (Contrastive v2)\n",
        "# ================================\n",
        "def train_variant_sensitive_glm(backbone, proj_head, tokenizer, seqs, device):\n",
        "\n",
        "    dataset = MutationContrastiveDataset(seqs, MUTATION_LEVELS)\n",
        "    dataloader = DataLoader(\n",
        "        dataset,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=True,\n",
        "        collate_fn=lambda b: collate_fn(b, tokenizer)\n",
        "    )\n",
        "\n",
        "    num_steps = EPOCHS * len(dataloader)\n",
        "    warmup_steps = int(num_steps * WARMUP_RATIO)\n",
        "\n",
        "    # backbone + head 모두 학습\n",
        "    params = list(backbone.parameters()) + list(proj_head.parameters())\n",
        "    optimizer = torch.optim.AdamW(params, lr=LR)\n",
        "    scheduler = get_cosine_schedule_with_warmup(\n",
        "        optimizer, warmup_steps, num_steps\n",
        "    )\n",
        "\n",
        "    backbone.train()\n",
        "    proj_head.train()\n",
        "\n",
        "    for epoch in range(EPOCHS):\n",
        "\n",
        "        total_loss = 0.0\n",
        "\n",
        "        for orig_enc, mut_token, mut_counts in tqdm(dataloader):\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            orig_ids = orig_enc[\"input_ids\"].to(device)\n",
        "            orig_mask = orig_enc[\"attention_mask\"].to(device)\n",
        "\n",
        "            emb_orig = forward_embedding(backbone, proj_head, orig_ids, orig_mask)\n",
        "\n",
        "            mut_counts = mut_counts.to(device)\n",
        "            B, L, A = mut_counts.shape\n",
        "            seq_len_est = orig_mask.sum(dim=1).unsqueeze(1)\n",
        "\n",
        "            loss_sum = 0.0\n",
        "\n",
        "            for i in range(L):\n",
        "                for j in range(A):\n",
        "                    enc = mut_token[i][j]\n",
        "                    m_ids = enc[\"input_ids\"].to(device)\n",
        "                    m_mask = enc[\"attention_mask\"].to(device)\n",
        "\n",
        "                    emb_mut = forward_embedding(backbone, proj_head, m_ids, m_mask)\n",
        "                    dist = cosine_distance(emb_orig, emb_mut)\n",
        "\n",
        "                    mut_ratio = mut_counts[:, i, j] / seq_len_est.squeeze(1)\n",
        "                    margin = BASE_MARGIN + ALPHA_MARGIN * torch.log1p(5 * mut_ratio)\n",
        "                    loss_level = F.relu(margin - dist).mean()\n",
        "\n",
        "                    loss_sum += loss_level\n",
        "\n",
        "            loss = loss_sum / (L * A)\n",
        "            loss.backward()\n",
        "\n",
        "            torch.nn.utils.clip_grad_norm_(params, 1.0)\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        print(f\"[Epoch {epoch+1}] Loss = {total_loss / len(dataloader):.4f}\")\n",
        "\n",
        "    return backbone, proj_head\n"
      ],
      "metadata": {
        "id": "GxIomS4wj8F6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# 5. Embedding Extraction\n",
        "# ================================\n",
        "class TestSeqDataset(Dataset):\n",
        "    def __init__(self, df):\n",
        "        self.ids = df[\"ID\"].tolist()\n",
        "        self.seqs = df[\"seq\"].astype(str).tolist()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        seq = center_crop(self.seqs[idx], MAX_SEQ_LEN)\n",
        "        return self.ids[idx], seq\n",
        "\n",
        "\n",
        "def collate_test(batch, tokenizer):\n",
        "    ids = [b[0] for b in batch]\n",
        "    seqs = [b[1] for b in batch]\n",
        "\n",
        "    enc = tokenizer(\n",
        "        seqs,\n",
        "        padding=True,\n",
        "        truncation=True,\n",
        "        max_length=MAX_SEQ_LEN,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "\n",
        "    return ids, enc\n",
        "\n",
        "\n",
        "def extract_embeddings(backbone, proj_head, tokenizer, df, device):\n",
        "    backbone.eval()\n",
        "    proj_head.eval()\n",
        "\n",
        "    ds = TestSeqDataset(df)\n",
        "    dl = DataLoader(\n",
        "        ds,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=False,\n",
        "        collate_fn=lambda b: collate_test(b, tokenizer)\n",
        "    )\n",
        "\n",
        "    all_ids = []\n",
        "    all_embs = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for ids, enc in tqdm(dl):\n",
        "\n",
        "            input_ids = enc[\"input_ids\"].to(device)\n",
        "            attn_mask = enc[\"attention_mask\"].to(device)\n",
        "\n",
        "            emb = forward_embedding(backbone, proj_head, input_ids, attn_mask)\n",
        "\n",
        "            all_ids.extend(ids)\n",
        "            all_embs.append(emb.cpu().numpy())\n",
        "\n",
        "    all_embs = np.vstack(all_embs)\n",
        "\n",
        "    sub = pd.read_csv(SAMPLE_SUB_PATH)\n",
        "    id_to_index = {id_: i for i, id_ in enumerate(all_ids)}\n",
        "\n",
        "    ordered = np.zeros((len(sub), EMBED_DIM), dtype=np.float32)\n",
        "\n",
        "    for i, id_ in enumerate(sub[\"ID\"].tolist()):\n",
        "        ordered[i] = all_embs[id_to_index[id_]]\n",
        "\n",
        "    emb_cols = [f\"emb_{i:04d}\" for i in range(EMBED_DIM)]\n",
        "    return pd.concat([sub[[\"ID\"]], pd.DataFrame(ordered, columns=emb_cols)], axis=1)"
      ],
      "metadata": {
        "id": "ratBagaRj-Yi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# 6. Main\n",
        "# ================================\n",
        "def main():\n",
        "\n",
        "    set_seed(SEED)\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(\"Device:\", device)\n",
        "\n",
        "    test_df = pd.read_csv(TEST_PATH)\n",
        "\n",
        "    tokenizer, backbone, proj_head = load_glm_model(MODEL_NAME, device)\n",
        "\n",
        "    if DO_TRAIN:\n",
        "        uniq = test_df[\"seq\"].astype(str).unique().tolist()\n",
        "        random.shuffle(uniq)\n",
        "        train_seqs = uniq[:MAX_TRAIN_SEQS]\n",
        "\n",
        "        backbone, proj_head = train_variant_sensitive_glm(\n",
        "            backbone, proj_head, tokenizer, train_seqs, device\n",
        "        )\n",
        "\n",
        "    submission_df = extract_embeddings(\n",
        "        backbone, proj_head, tokenizer, test_df, device\n",
        "    )\n",
        "\n",
        "    submission_df.to_csv(OUTPUT_PATH, index=False)\n",
        "    print(\"Saved:\", OUTPUT_PATH)\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450,
          "referenced_widgets": [
            "4cf8a54cf77a42de8798a6288b311b20",
            "50037110a26444b39ac9f4becb34856f",
            "3ba86012cc8646e99fa209cc96711f3d",
            "89a98d645bdd42ce955509a276ee89c8",
            "fabb1dcb7a3c4e71a09939cff0b145b0",
            "2f4c908433a446819ef5c62902620748",
            "980e394270234c4ebc38ea393f5ec8b8",
            "b89b058229ef4ceb9843dbac045f3b0e",
            "a46faa696ef04d61a587e5f03a3da045",
            "9390a455b94d46c5bae7c255b0b4c5ad",
            "9b8da269c6e448a99ea4f0c7f9f9a6d7",
            "7aac0cd7543f4364a21effbed75f338c",
            "5b6888e277c84ba2ac132bcf2669fab6",
            "2dd9fbf2f16d4910a476d06f650b596f",
            "dc3b31dbd1494ba5aa98f588bb78acca",
            "6250a29bed0944079fdf884658476f31",
            "0cfa22dce8b847df8fc9375f907bd19c",
            "df716426995e47b8972339e4c2bab2be",
            "1ad92820d0d84bdcbabd144135850008",
            "30b7217b88814e5eb6fea4858a05022a",
            "2fa97ba877844ddc94d08aab0604da25",
            "982c0dfa8f704b5b87d222a2ffa9ae41"
          ]
        },
        "id": "YMUA0n5TkA7S",
        "outputId": "009be160-f2fe-451e-8d4b-c7b9120095d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of EsmModel were not initialized from the model checkpoint at InstaDeepAI/nucleotide-transformer-v2-50m-multi-species and are newly initialized: ['encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.output.dense.bias', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.output.dense.bias', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.output.dense.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.output.dense.bias', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.output.dense.bias', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.output.dense.bias', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.output.dense.bias', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.output.dense.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.output.dense.bias', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.output.dense.bias', 'pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of EsmModel were not initialized from the model checkpoint at InstaDeepAI/nucleotide-transformer-v2-50m-multi-species and are newly initialized because the shapes did not match:\n",
            "- encoder.layer.0.intermediate.dense.weight: found shape torch.Size([4096, 512]) in the checkpoint and torch.Size([2048, 512]) in the model instantiated\n",
            "- encoder.layer.1.intermediate.dense.weight: found shape torch.Size([4096, 512]) in the checkpoint and torch.Size([2048, 512]) in the model instantiated\n",
            "- encoder.layer.10.intermediate.dense.weight: found shape torch.Size([4096, 512]) in the checkpoint and torch.Size([2048, 512]) in the model instantiated\n",
            "- encoder.layer.11.intermediate.dense.weight: found shape torch.Size([4096, 512]) in the checkpoint and torch.Size([2048, 512]) in the model instantiated\n",
            "- encoder.layer.2.intermediate.dense.weight: found shape torch.Size([4096, 512]) in the checkpoint and torch.Size([2048, 512]) in the model instantiated\n",
            "- encoder.layer.3.intermediate.dense.weight: found shape torch.Size([4096, 512]) in the checkpoint and torch.Size([2048, 512]) in the model instantiated\n",
            "- encoder.layer.4.intermediate.dense.weight: found shape torch.Size([4096, 512]) in the checkpoint and torch.Size([2048, 512]) in the model instantiated\n",
            "- encoder.layer.5.intermediate.dense.weight: found shape torch.Size([4096, 512]) in the checkpoint and torch.Size([2048, 512]) in the model instantiated\n",
            "- encoder.layer.6.intermediate.dense.weight: found shape torch.Size([4096, 512]) in the checkpoint and torch.Size([2048, 512]) in the model instantiated\n",
            "- encoder.layer.7.intermediate.dense.weight: found shape torch.Size([4096, 512]) in the checkpoint and torch.Size([2048, 512]) in the model instantiated\n",
            "- encoder.layer.8.intermediate.dense.weight: found shape torch.Size([4096, 512]) in the checkpoint and torch.Size([2048, 512]) in the model instantiated\n",
            "- encoder.layer.9.intermediate.dense.weight: found shape torch.Size([4096, 512]) in the checkpoint and torch.Size([2048, 512]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1714 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4cf8a54cf77a42de8798a6288b311b20"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 1] Loss = 4.3056\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1714 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7aac0cd7543f4364a21effbed75f338c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved: submission_v2_fixed.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#너무 실행시간이 길어서 다른코드"
      ],
      "metadata": {
        "id": "8UMZBNc1ZR8t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -q transformers tqdm"
      ],
      "metadata": {
        "id": "WdlOs-rTZVto"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "from typing import List, Tuple\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForMaskedLM\n"
      ],
      "metadata": {
        "id": "0VLEj_J8wCcz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# 0. 설정값 (필요하면 여기만 수정)\n",
        "# ================================\n",
        "MODEL_NAME = \"InstaDeepAI/nucleotide-transformer-v2-50m-multi-species\"\n",
        "\n",
        "TEST_PATH = \"test.csv\"                  # 대회 제공 test.csv 경로\n",
        "SAMPLE_SUB_PATH = \"sample_submission.csv\"\n",
        "OUTPUT_PATH = \"submission_ntv2_fast.csv\"\n",
        "\n",
        "MAX_SEQ_LEN = 256                         # 토큰 최대 길이 (512보다 줄여 속도 ↑)\n",
        "BATCH_SIZE = 16                           # GPU 여유되면 32로 키워도 됨\n",
        "SEED = 2025\n"
      ],
      "metadata": {
        "id": "59gWWc6awEER"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# 1. 유틸 함수들\n",
        "# ================================\n",
        "def set_seed(seed: int = 42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "\n",
        "def mean_pool(last_hidden_state: torch.Tensor, attention_mask: torch.Tensor) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    pad 토큰을 제외하고 token dimension 평균을 내서 [batch, hidden] 임베딩 생성\n",
        "    \"\"\"\n",
        "    mask = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n",
        "    masked_hidden = last_hidden_state * mask\n",
        "    summed = masked_hidden.sum(dim=1)\n",
        "    counts = mask.sum(dim=1).clamp(min=1e-6)\n",
        "    return summed / counts\n"
      ],
      "metadata": {
        "id": "bm-uVwplwFeP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# 2. Dataset & collate\n",
        "# ================================\n",
        "class TestSeqDataset(Dataset):\n",
        "    def __init__(self, df: pd.DataFrame):\n",
        "        self.ids = df[\"ID\"].tolist()\n",
        "        self.seqs = df[\"seq\"].astype(str).tolist()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.ids[idx], self.seqs[idx]\n",
        "\n",
        "\n",
        "def collate_test(batch, tokenizer, max_len: int):\n",
        "    ids = [b[0] for b in batch]\n",
        "    seqs = [b[1] for b in batch]\n",
        "    enc = tokenizer(\n",
        "        seqs,\n",
        "        padding=True,\n",
        "        truncation=True,\n",
        "        max_length=max_len,\n",
        "        return_tensors=\"pt\",\n",
        "    )\n",
        "    return ids, enc\n"
      ],
      "metadata": {
        "id": "fC5W4uLUwJdX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# 3. 모델 로드\n",
        "# ================================\n",
        "def load_glm_model(model_name: str, device: torch.device):\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
        "\n",
        "    # fp16로 줄이고 싶으면 torch_dtype=torch.float16 옵션을 써도 됨\n",
        "    model = AutoModelForMaskedLM.from_pretrained(\n",
        "        model_name,\n",
        "        trust_remote_code=True,\n",
        "        # torch_dtype=torch.float16   # GPU + 메모리 여유 있으면 주석 해제\n",
        "    )\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    return tokenizer, model\n"
      ],
      "metadata": {
        "id": "ezf2V4eBwLMq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# 4. 임베딩 추출\n",
        "# ================================\n",
        "def extract_embeddings(\n",
        "    model,\n",
        "    tokenizer,\n",
        "    test_df: pd.DataFrame,\n",
        "    sample_sub: pd.DataFrame,\n",
        "    device: torch.device,\n",
        ") -> pd.DataFrame:\n",
        "    dataset = TestSeqDataset(test_df)\n",
        "    dataloader = DataLoader(\n",
        "        dataset,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=False,\n",
        "        collate_fn=lambda batch: collate_test(batch, tokenizer, MAX_SEQ_LEN),\n",
        "    )\n",
        "\n",
        "    all_ids = []\n",
        "    all_embs = []\n",
        "\n",
        "    hidden_size = model.config.hidden_size  # 이 모델은 512\n",
        "    print(\"hidden_size (embed_dim):\", hidden_size)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for ids, enc in tqdm(dataloader, desc=\"Extracting embeddings\"):\n",
        "            input_ids = enc[\"input_ids\"].to(device)\n",
        "            attn_mask = enc[\"attention_mask\"].to(device)\n",
        "\n",
        "            outputs = model(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attn_mask,\n",
        "                output_hidden_states=True,\n",
        "            )\n",
        "            last_hidden = outputs.hidden_states[-1]  # [B, L, H]\n",
        "            emb = mean_pool(last_hidden, attn_mask)  # [B, H]\n",
        "\n",
        "            emb = emb.detach().cpu().numpy().astype(np.float32)\n",
        "            all_ids.extend(ids)\n",
        "            all_embs.append(emb)\n",
        "\n",
        "    all_embs = np.vstack(all_embs)  # [N, H]\n",
        "\n",
        "    # sample_submission 의 ID 순서에 맞춰 정렬\n",
        "    id_to_index = {id_: i for i, id_ in enumerate(all_ids)}\n",
        "    ordered_embs = np.zeros((len(sample_sub), hidden_size), dtype=np.float32)\n",
        "\n",
        "    for i, id_ in enumerate(sample_sub[\"ID\"].tolist()):\n",
        "        idx = id_to_index[id_]\n",
        "        ordered_embs[i] = all_embs[idx]\n",
        "\n",
        "    emb_cols = [f\"emb_{i:04d}\" for i in range(hidden_size)]\n",
        "    emb_df = pd.DataFrame(ordered_embs, columns=emb_cols)\n",
        "    out_df = pd.concat([sample_sub[[\"ID\"]], emb_df], axis=1)\n",
        "    return out_df\n"
      ],
      "metadata": {
        "id": "4eJyc2_BwMoo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# 5. main\n",
        "# ================================\n",
        "def main():\n",
        "    set_seed(SEED)\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(\"Device:\", device)\n",
        "\n",
        "    test_df = pd.read_csv(TEST_PATH)\n",
        "    sample_sub = pd.read_csv(SAMPLE_SUB_PATH)\n",
        "    print(\"test shape:\", test_df.shape)\n",
        "\n",
        "    tokenizer, model = load_glm_model(MODEL_NAME, device)\n",
        "\n",
        "    submission_df = extract_embeddings(\n",
        "        model=model,\n",
        "        tokenizer=tokenizer,\n",
        "        test_df=test_df,\n",
        "        sample_sub=sample_sub,\n",
        "        device=device,\n",
        "    )\n",
        "\n",
        "    submission_df.to_csv(OUTPUT_PATH, index=False)\n",
        "    print(\"Saved submission to:\", OUTPUT_PATH)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123,
          "referenced_widgets": [
            "4316724857a84646a09aecd4df32cc81",
            "c2371eec099248efbeb96b5acd0ebd4a",
            "b699f42c711e4cdda1d34fb65abda1b3",
            "3b837ea4c9f74965bbc15e0a0e1cfc52",
            "ca3d481d0c0648a7906211355205363e",
            "c879132defe141eabeaa4082d30b007d",
            "b3c52e4c7c08452588788764ea8b9a88",
            "8a58dc49971943c1ab92b19224816b05",
            "34f851007cda49e4ac0c1e22163a837b",
            "2412c3431d2a449c817ca713bd3518f7",
            "e5605d76bb85480883f55d86f4cee02a"
          ]
        },
        "id": "8yfrr7SpwOad",
        "outputId": "f01134d9-1e30-4b9c-c27a-2ff28aba7ac6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cpu\n",
            "test shape: (13711, 2)\n",
            "hidden_size (embed_dim): 512\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Extracting embeddings:   0%|          | 0/857 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4316724857a84646a09aecd4df32cc81"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved submission to: ./submission_ntv2_fast.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#제미나이 코드"
      ],
      "metadata": {
        "id": "Sf8ExfrvD2ha"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "# =========================================================\n",
        "# 1. (Colab일 때만) 필요한 라이브러리 설치\n",
        "#    - 이미 설치되어 있으면 이 셀은 건너뛰어도 됩니다.\n",
        "# =========================================================\n",
        "# !pip install transformers datasets accelerate pandas numpy torch tqdm\n"
      ],
      "metadata": {
        "id": "JGADjSPjD347"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# 2. 라이브러리 임포트\n",
        "# =========================================================\n",
        "import os\n",
        "import random\n",
        "from pathlib import Path\n",
        "from typing import List, Tuple\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AutoTokenizer, AutoModelForMaskedLM"
      ],
      "metadata": {
        "id": "h0P9k4qLFAMN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------------------------------\n",
        "# 디바이스 설정 (GPU 사용 가능 시 사용)\n",
        "# ---------------------------------------------------------\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"사용 장치: {DEVICE}\")\n",
        "\n",
        "DATA_PATH = Path(\"./\")  # test.csv, sample_submission.csv 있는 경로 기준\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3qJ9yc-FBl2",
        "outputId": "66ec8733-0496-456b-9f24-39bcb9792f98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "사용 장치: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# 3. 재현성 위한 시드 고정\n",
        "# =========================================================\n",
        "def set_seed(seed: int = 2025):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)"
      ],
      "metadata": {
        "id": "bsDX_K2gFGFe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# 4. 데이터셋 클래스\n",
        "#    - 개별 샘플은 토큰화하지 않고 seq 문자열만 넘기고,\n",
        "#      collate_fn에서 한 번에 배치 토큰화 -> 더 빠름\n",
        "# =========================================================\n",
        "class SequenceDataset(Dataset):\n",
        "    def __init__(self, data: pd.DataFrame):\n",
        "        self.ids = data[\"ID\"].tolist()\n",
        "        self.sequences = data[\"seq\"].tolist()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sequences)\n",
        "\n",
        "    def __getitem__(self, idx: int) -> dict:\n",
        "        return {\n",
        "            \"id\": self.ids[idx],\n",
        "            \"seq\": self.sequences[idx],\n",
        "        }"
      ],
      "metadata": {
        "id": "hzwHWzAcFG2o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# 5. Pooling 함수 (Mean + Max Concatenation)\n",
        "#    - pad 토큰은 mask로 제거\n",
        "# =========================================================\n",
        "def concat_mean_max_pooling(\n",
        "    last_hidden_state: torch.Tensor,  # [B, L, H]\n",
        "    attention_mask: torch.Tensor,     # [B, L]\n",
        ") -> torch.Tensor:\n",
        "    # mask: [B, L, 1]\n",
        "    mask = attention_mask.unsqueeze(-1).float()\n",
        "\n",
        "    # ----- Mean Pooling -----\n",
        "    masked_hidden = last_hidden_state * mask\n",
        "    sum_hidden = masked_hidden.sum(dim=1)               # [B, H]\n",
        "    token_count = mask.sum(dim=1).clamp(min=1e-6)       # [B, 1]\n",
        "    mean_emb = sum_hidden / token_count                 # [B, H]\n",
        "\n",
        "    # ----- Max Pooling -----\n",
        "    # pad 위치는 아주 작은 값으로 채워서 max에서 제외\n",
        "    very_neg = torch.finfo(last_hidden_state.dtype).min\n",
        "    hidden_for_max = last_hidden_state.masked_fill(\n",
        "        attention_mask.unsqueeze(-1) == 0, very_neg\n",
        "    )\n",
        "    max_emb, _ = hidden_for_max.max(dim=1)              # [B, H]\n",
        "\n",
        "    # ----- Concatenate -----\n",
        "    seq_emb = torch.cat([mean_emb, max_emb], dim=1)     # [B, 2H]\n",
        "    return seq_emb\n"
      ],
      "metadata": {
        "id": "RwltUjrfFJB8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# 6. 임베딩 추출 함수\n",
        "# =========================================================\n",
        "def get_embeddings(\n",
        "    model: AutoModelForMaskedLM,\n",
        "    tokenizer: AutoTokenizer,\n",
        "    dataloader: DataLoader,\n",
        "    max_len: int,\n",
        "    device: torch.device,\n",
        ") -> Tuple[np.ndarray, List[str]]:\n",
        "    model.eval()\n",
        "    all_embs = []\n",
        "    all_ids = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(dataloader, desc=\"Calculating Embeddings\"):\n",
        "            ids = batch[\"id\"]\n",
        "            seqs = batch[\"seq\"]\n",
        "\n",
        "            # 배치 토큰화\n",
        "            tokenized = tokenizer(\n",
        "                seqs,\n",
        "                padding=\"max_length\",\n",
        "                truncation=True,\n",
        "                max_length=max_len,\n",
        "                return_tensors=\"pt\",\n",
        "            )\n",
        "            input_ids = tokenized[\"input_ids\"].to(device)\n",
        "            attention_mask = tokenized[\"attention_mask\"].to(device)\n",
        "\n",
        "            # 🔴 여기 수정: hidden_states를 켜고, 마지막 레이어를 직접 꺼내쓰기\n",
        "            outputs = model(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask,\n",
        "                output_hidden_states=True,   # ✅ 켜기\n",
        "                return_dict=True,            # 안전하게 dict 형태 보장\n",
        "            )\n",
        "\n",
        "            # MaskedLMOutput 에는 last_hidden_state가 없으니까\n",
        "            # hidden_states 튜플의 마지막 것을 사용\n",
        "            last_hidden = outputs.hidden_states[-1]   # ✅ [B, L, H]\n",
        "\n",
        "            # Mean + Max pooling 결합\n",
        "            seq_emb = concat_mean_max_pooling(last_hidden, attention_mask)  # [B, 2H]\n",
        "\n",
        "            all_embs.append(seq_emb.cpu())\n",
        "            all_ids.extend(ids)\n",
        "\n",
        "    emb_tensor = torch.vstack(all_embs).float()\n",
        "    emb_np = emb_tensor.numpy()\n",
        "    N, H = emb_np.shape\n",
        "    print(f\"✅ 최종 임베딩 차원: {N} x {H}\")\n",
        "    return emb_np, all_ids\n",
        "\n"
      ],
      "metadata": {
        "id": "J37hxPExFK9e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# 7. 메인 실행 블록\n",
        "# =========================================================\n",
        "def main():\n",
        "    set_seed(2025)\n",
        "\n",
        "    # ---------- 하이퍼파라미터 ----------\n",
        "    # v2-50m : hidden_size=512 ⇒ mean+max concat => 1024차원 (2048 이내)\n",
        "    MODEL_NAME = \"InstaDeepAI/nucleotide-transformer-v2-50m-multi-species\"\n",
        "    MAX_LENGTH = 256      # 시퀀스 길이에 따라 256~512 정도로 조정\n",
        "    BATCH_SIZE = 32       # GPU 여유 없으면 16으로 줄이기\n",
        "    SUBMISSION_FILE_NAME = \"submission_ntv2_concat_pooling.csv\"\n",
        "\n",
        "    # ---------- 데이터 로드 ----------\n",
        "    test_df = pd.read_csv(\"test.csv\")\n",
        "    print(f\"테스트 데이터셋 크기: {len(test_df)}\")\n",
        "\n",
        "    # ---------- 모델/토크나이저 로드 ----------\n",
        "    print(\"모델 및 토크나이저 로드 시작...\")\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\n",
        "        MODEL_NAME,\n",
        "        trust_remote_code=True,\n",
        "    )\n",
        "    model = AutoModelForMaskedLM.from_pretrained(\n",
        "        MODEL_NAME,\n",
        "        trust_remote_code=True,\n",
        "        # GPU + 메모리 여유 충분하면 아래 주석 해제해서 half precision 사용 가능\n",
        "        # torch_dtype=torch.float16,\n",
        "    )\n",
        "    model.to(DEVICE)\n",
        "    print(\"모델 로드 완료.\")\n",
        "\n",
        "    # ---------- 데이터셋/로더 ----------\n",
        "    test_dataset = SequenceDataset(test_df)\n",
        "    test_dataloader = DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=False,\n",
        "        num_workers=2,      # Colab CPU 상황에 따라 0~2 정도\n",
        "        pin_memory=True if DEVICE.type == \"cuda\" else False,\n",
        "    )\n",
        "\n",
        "    # ---------- 임베딩 추출 ----------\n",
        "    emb_np, all_ids = get_embeddings(\n",
        "        model=model,\n",
        "        tokenizer=tokenizer,\n",
        "        dataloader=test_dataloader,\n",
        "        max_len=MAX_LENGTH,\n",
        "        device=DEVICE,\n",
        "    )\n",
        "\n",
        "    # ---------- 제출 파일 생성 ----------\n",
        "    H = emb_np.shape[1]\n",
        "    emb_cols = [f\"emb_{i:04d}\" for i in range(H)]\n",
        "    emb_df = pd.DataFrame(emb_np, columns=emb_cols)\n",
        "\n",
        "    # ID–임베딩 합치기\n",
        "    tmp_df = pd.DataFrame({\"ID\": all_ids})\n",
        "    tmp_df = pd.concat([tmp_df, emb_df], axis=1)\n",
        "\n",
        "    # test_df의 ID 순서를 유지\n",
        "    submission_df = test_df[[\"ID\"]].merge(tmp_df, on=\"ID\", how=\"left\")\n",
        "\n",
        "    submission_df.to_csv(DATA_PATH / SUBMISSION_FILE_NAME, index=False, encoding=\"utf-8\")\n",
        "    print(f\"🎉 제출 파일 생성 완료: {SUBMISSION_FILE_NAME}\")\n",
        "    print(submission_df.head())\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 546,
          "referenced_widgets": [
            "b1443574c51f4765aa73bd1713f1cca9",
            "72ed465c15d9473586e83f388ec15436",
            "fdd3eddea55d411cbc3327df2c9b7c2d",
            "27989a4271584fc1a59f696e554bc871",
            "4f88fa189a2a4776977006c257d0358e",
            "7981207a413a429ea74701931853b8a2",
            "c125f240a7284646afdfcbad0834b40c",
            "91bf1474b04a47508b03eceb8d4dd55f",
            "58c4f58f1b234820b0c3d1697c4003ea",
            "36c801a085fc44c5844c283abc9b6098",
            "d3c437e8a9da46848ef207bc19c1f8d9"
          ]
        },
        "id": "YmW8vSV6FL31",
        "outputId": "f93f0366-3245-4cf3-f146-0d5d2082d882"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "테스트 데이터셋 크기: 13711\n",
            "모델 및 토크나이저 로드 시작...\n",
            "모델 로드 완료.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Calculating Embeddings:   0%|          | 0/429 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b1443574c51f4765aa73bd1713f1cca9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ 최종 임베딩 차원: 13711 x 1024\n",
            "🎉 제출 파일 생성 완료: submission_ntv2_concat_pooling.csv\n",
            "            ID  emb_0000  emb_0001  emb_0002  emb_0003  emb_0004  emb_0005  \\\n",
            "0  TEST_000000 -0.076687  0.532987  0.250104  0.095763  0.156266  0.105156   \n",
            "1  TEST_000001 -0.085685  0.429889  0.162488  0.018770  0.180672  0.030552   \n",
            "2  TEST_000002 -0.132982  0.442900  0.154394  0.054666  0.087602  0.050151   \n",
            "3  TEST_000003 -0.067654  0.335053  0.164019  0.050935  0.122121  0.061331   \n",
            "4  TEST_000004  0.001792  0.429978  0.129435  0.022114  0.160501  0.128668   \n",
            "\n",
            "   emb_0006  emb_0007  emb_0008  ...  emb_1014  emb_1015  emb_1016  emb_1017  \\\n",
            "0 -0.098269  0.237808 -0.060832  ...  1.130631  0.956810  1.064700  0.892267   \n",
            "1 -0.173395  0.071261  0.031437  ...  1.194993  1.177694  1.312644  0.752649   \n",
            "2 -0.168084  0.469866  0.008924  ...  1.287498  1.098501  1.016127  0.657049   \n",
            "3 -0.241115  0.446619  0.027432  ...  1.207277  0.906364  0.979558  0.993381   \n",
            "4 -0.150665  0.328996 -0.111540  ...  0.912517  1.120702  1.151519  0.924641   \n",
            "\n",
            "   emb_1018  emb_1019  emb_1020  emb_1021  emb_1022  emb_1023  \n",
            "0  0.866988  0.677941  1.195900  0.896726  0.896982  0.729049  \n",
            "1  1.250116  0.651354  0.771829  0.742858  0.825787  0.848082  \n",
            "2  1.110743  0.962714  0.812531  0.756515  0.945753  0.766471  \n",
            "3  1.272544  0.865799  0.835023  0.721450  0.780638  0.799890  \n",
            "4  0.854788  0.995779  1.101849  1.041460  0.799261  1.068319  \n",
            "\n",
            "[5 rows x 1025 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 첫번째 코드 개선 다른버전"
      ],
      "metadata": {
        "id": "UWuS0DGd1MH9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "# 구글 코랩에서 실행 가능하며, `test.csv`와 `sample_submission.csv`가 현재 디렉토리에 있어야 합니다.\n",
        "# ----------------------------------------------------------------------\n",
        "# 1. 필수 라이브러리 설치 (Colab용)\n",
        "# ----------------------------------------------------------------------\n",
        "!pip install transformers datasets accelerate pandas numpy torch tqdm\n",
        "\n",
        "# ----------------------------------------------------------------------\n",
        "# 2. 라이브러리 임포트 및 유틸리티\n",
        "# ----------------------------------------------------------------------\n",
        "import os\n",
        "import random\n",
        "import math\n",
        "from typing import List, Tuple\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModel, get_linear_schedule_with_warmup"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wLLmoKMO1Por",
        "outputId": "2e941461-f8e8-4405-c8d5-5f917cf1133e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.2)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.12.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.13.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.11.12)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.22.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# 0. 설정값 (하이퍼파라미터 튜닝 영역)\n",
        "# ================================\n",
        "# v2-50m 모델 사용\n",
        "MODEL_NAME = \"InstaDeepAI/nucleotide-transformer-v2-50m-multi-species\"\n",
        "\n",
        "TEST_PATH = \"test.csv\"\n",
        "SAMPLE_SUB_PATH = \"sample_submission.csv\"\n",
        "OUTPUT_PATH = \"submission_ntv2_boosted_contrastive.csv\"\n",
        "\n",
        "MAX_SEQ_LEN = 512                                # 토큰 최대 길이\n",
        "BASE_HIDDEN_DIM = 512                            # v2-50m 모델의 기본 hidden_size\n",
        "EMBED_DIM = BASE_HIDDEN_DIM * 2                  # Mean + Max Pooling으로 1024차원 사용\n",
        "\n",
        "DO_TRAIN = True                                  # 파인튜닝 여부 (대회에서는 True 권장)\n",
        "MAX_TRAIN_SEQS = 20000                           # test 중 학습에 쓸 최대 시퀀스 수 (속도 고려)\n",
        "EPOCHS = 1                                       # Colab 환경 최적화\n",
        "BATCH_SIZE = 8\n",
        "LR = 1e-5                                        # 학습률 조정 (1e-5 ~ 3e-5)\n",
        "WARMUP_RATIO = 0.05\n",
        "\n",
        "# Triplet Contrastive Learning 설정\n",
        "# Mut_A: 작은 변이 (Positive 역할), Mut_B: 큰 변이 (Negative 역할)\n",
        "MUTATION_LEVEL_A = 0.002                         # 0.2% SNV (작은 변이)\n",
        "MUTATION_LEVEL_B = 0.01                          # 1.0% SNV (큰 변이)\n",
        "\n",
        "# Triplet Loss Margin: dist(Anchor, Positive) + MARGIN < dist(Anchor, Negative)\n",
        "# Margin을 동적으로 설정: BASE_MARGIN + (Mut_B - Mut_A) * ALPHA_MARGIN\n",
        "TRIPLET_MARGIN = 0.2\n",
        "ALPHA_MARGIN_SCALE = 1.0 # 동적 마진 스케일 조정 (PCC 개선)\n",
        "\n",
        "SEED = 2025"
      ],
      "metadata": {
        "id": "rwrIZqWV1TFh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# 1. 유틸 함수들\n",
        "# ================================\n",
        "def set_seed(seed: int = 42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "def mutate_sequence_snvs(seq: str, mutation_ratio: float) -> Tuple[str, int]:\n",
        "    \"\"\"\n",
        "    주어진 DNA 염기열에 대해 SNV(single nucleotide variants)만 랜덤으로 넣어서\n",
        "    '조금 다른' variant 시퀀스를 만든다.\n",
        "    \"\"\"\n",
        "    bases = [\"A\", \"C\", \"G\", \"T\"]\n",
        "    seq = seq.upper()\n",
        "    length = len(seq)\n",
        "\n",
        "    # 최소 1개 변이 보장\n",
        "    num_mutations = max(1, int(length * mutation_ratio))\n",
        "\n",
        "    if num_mutations >= length:\n",
        "        num_mutations = length // 2 if length >= 2 else 1\n",
        "\n",
        "    positions = random.sample(range(length), num_mutations)\n",
        "    seq_list = list(seq)\n",
        "\n",
        "    for pos in positions:\n",
        "        original = seq_list[pos]\n",
        "        candidates = [b for b in bases if b != original]\n",
        "        if not candidates:\n",
        "            continue\n",
        "        seq_list[pos] = random.choice(candidates)\n",
        "\n",
        "    mutated = \"\".join(seq_list)\n",
        "    return mutated, num_mutations\n",
        "\n",
        "def get_pooled_embedding(last_hidden_state: torch.Tensor, attention_mask: torch.Tensor) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Mean Pooling과 Max Pooling을 결합하여 (Concatenative Pooling) 임베딩을 추출합니다.\n",
        "    [B, L, H] -> [B, 2*H]\n",
        "    \"\"\"\n",
        "    # 1. Mean Pooling (패딩 제외)\n",
        "    mask = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n",
        "    masked_hidden = last_hidden_state * mask\n",
        "    summed = masked_hidden.sum(dim=1)\n",
        "    counts = mask.sum(dim=1).clamp(min=1e-6)\n",
        "    mean_emb = summed / counts # [B, H]\n",
        "\n",
        "    # 2. Max Pooling (패딩 제외)\n",
        "    # 패딩 위치는 -inf로 설정하여 Max Pooling 시 선택되지 않도록 함\n",
        "    masked_hidden_max = last_hidden_state.masked_fill(~mask.bool(), -1e9)\n",
        "    max_emb, _ = torch.max(masked_hidden_max, dim=1) # [B, H]\n",
        "\n",
        "    # 3. Concatenate (결합)\n",
        "    return torch.cat((mean_emb, max_emb), dim=1) # [B, 2*H]\n",
        "\n",
        "def cosine_distance(a: torch.Tensor, b: torch.Tensor) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    코사인 거리: 1 - cos_sim\n",
        "    \"\"\"\n",
        "    return 1.0 - F.cosine_similarity(a, b)"
      ],
      "metadata": {
        "id": "U7ik7RJK1YUA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# 2. Dataset 정의 (Triplet Loss 구조)\n",
        "# ================================\n",
        "class MutationContrastiveDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Anchor(Original), Positive(Small Mutation), Negative(Large Mutation) Triplet을 생성\n",
        "    \"\"\"\n",
        "    def __init__(self, seq_list: List[str]):\n",
        "        self.seqs = seq_list\n",
        "        # 작은 변이: Positive 역할을 하여 거리를 가깝게 유도\n",
        "        self.mutation_ratio_P = MUTATION_LEVEL_A\n",
        "        # 큰 변이: Negative 역할을 하여 거리를 멀게 유도\n",
        "        self.mutation_ratio_N = MUTATION_LEVEL_B\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.seqs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        seq = self.seqs[idx]\n",
        "\n",
        "        # P: Original - Small Mutation (Positive Pair)\n",
        "        mut_P, n_mut_P = mutate_sequence_snvs(seq, self.mutation_ratio_P)\n",
        "\n",
        "        # N: Original - Large Mutation (Negative Pair)\n",
        "        mut_N, n_mut_N = mutate_sequence_snvs(seq, self.mutation_ratio_N)\n",
        "\n",
        "        return {\n",
        "            \"anchor\": seq,\n",
        "            \"positive\": mut_P,\n",
        "            \"negative\": mut_N,\n",
        "            \"num_mut_P\": n_mut_P,\n",
        "            \"num_mut_N\": n_mut_N,\n",
        "        }\n",
        "\n",
        "def collate_fn(batch, tokenizer, max_len: int):\n",
        "    anchors = [b[\"anchor\"] for b in batch]\n",
        "    positives = [b[\"positive\"] for b in batch]\n",
        "    negatives = [b[\"negative\"] for b in batch]\n",
        "\n",
        "    num_mut_P = [b[\"num_mut_P\"] for b in batch]\n",
        "    num_mut_N = [b[\"num_mut_N\"] for b in batch]\n",
        "\n",
        "    # 모든 시퀀스를 한 번에 토큰화\n",
        "    all_seqs = anchors + positives + negatives\n",
        "\n",
        "    enc = tokenizer(\n",
        "        all_seqs,\n",
        "        padding=True,\n",
        "        truncation=True,\n",
        "        max_length=max_len,\n",
        "        return_tensors=\"pt\",\n",
        "    )\n",
        "\n",
        "    # 배치 크기\n",
        "    B = len(anchors)\n",
        "\n",
        "    # 결과 분리\n",
        "    enc_A = {k: v[:B] for k, v in enc.items()}\n",
        "    enc_P = {k: v[B:2*B] for k, v in enc.items()}\n",
        "    enc_N = {k: v[2*B:] for k, v in enc.items()}\n",
        "\n",
        "    num_mut_tensor = torch.tensor([num_mut_P, num_mut_N], dtype=torch.float32).T # [B, 2]\n",
        "\n",
        "    return enc_A, enc_P, enc_N, num_mut_tensor"
      ],
      "metadata": {
        "id": "ScPHw6Ey1bXl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# 3. 모델 아키텍처 및 로드 (Dropout 추가)\n",
        "# ================================\n",
        "class VariantSensitiveGLM(nn.Module):\n",
        "    \"\"\"\n",
        "    기존 AutoModel 위에 Dropout 레이어를 추가하여 Fine-Tuning 안정성 및 일반화 개선\n",
        "    \"\"\"\n",
        "    def __init__(self, model_name: str, hidden_dropout_prob: float = 0.1):\n",
        "        super().__init__()\n",
        "        # AutoModelForMaskedLM 대신, 임베딩 추출에 더 적합한 AutoModel 사용\n",
        "        self.base_model = AutoModel.from_pretrained(\n",
        "            model_name,\n",
        "            trust_remote_code=True,\n",
        "            ignore_mismatched_sizes=True # MLM 헤드 가중치 불일치 무시\n",
        "        )\n",
        "        # 임베딩 추출 시 안정성을 위해 마지막 히든 스테이트에 Dropout 적용\n",
        "        self.dropout = nn.Dropout(hidden_dropout_prob)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.base_model(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            output_hidden_states=True,\n",
        "            return_dict=True\n",
        "        )\n",
        "\n",
        "        # 마지막 히든 스테이트에 Dropout 적용\n",
        "        last_hidden_state = self.dropout(outputs.last_hidden_state)\n",
        "\n",
        "        # Concatenative Pooling을 통해 최종 임베딩 벡터 반환\n",
        "        pooled_emb = get_pooled_embedding(last_hidden_state, attention_mask)\n",
        "\n",
        "        return pooled_emb # [B, 2*H]\n",
        "\n",
        "def load_glm_model(model_name: str, device: torch.device):\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
        "    model = VariantSensitiveGLM(model_name)\n",
        "    model.to(device)\n",
        "\n",
        "    return tokenizer, model"
      ],
      "metadata": {
        "id": "QXfSd0tK1etp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# 4. 파인튜닝 루프 (Triplet Loss 적용)\n",
        "# ================================\n",
        "def train_variant_sensitive_glm(\n",
        "    model: VariantSensitiveGLM,\n",
        "    tokenizer: AutoTokenizer,\n",
        "    train_seqs: List[str],\n",
        "    device: torch.device,\n",
        "):\n",
        "    dataset = MutationContrastiveDataset(train_seqs)\n",
        "    dataloader = DataLoader(\n",
        "        dataset,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=True,\n",
        "        collate_fn=lambda batch: collate_fn(batch, tokenizer, MAX_SEQ_LEN),\n",
        "    )\n",
        "\n",
        "    num_training_steps = EPOCHS * len(dataloader)\n",
        "    warmup_steps = int(num_training_steps * WARMUP_RATIO)\n",
        "\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=LR)\n",
        "    scheduler = get_linear_schedule_with_warmup(\n",
        "        optimizer,\n",
        "        num_warmup_steps=warmup_steps,\n",
        "        num_training_steps=num_training_steps,\n",
        "    )\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    # 동적 마진 계산: mutation_ratio_N - mutation_ratio_P = 0.01 - 0.002 = 0.008\n",
        "    # Triplet Loss Margin을 동적 비율에 따라 조정\n",
        "    # 이는 변이 크기에 따른 거리 차이를 강제하여 PCC를 개선하는 데 도움을 줌\n",
        "    dynamic_margin = TRIPLET_MARGIN + ALPHA_MARGIN_SCALE * (MUTATION_LEVEL_B - MUTATION_LEVEL_A)\n",
        "    dynamic_margin = torch.tensor(dynamic_margin, dtype=torch.float32).to(device)\n",
        "    print(f\"Triplet Loss Margin: {dynamic_margin.item():.4f}\")\n",
        "\n",
        "\n",
        "    for epoch in range(EPOCHS):\n",
        "        epoch_loss = 0.0\n",
        "        progress_bar = tqdm(dataloader, desc=f\"Epoch {epoch+1}/{EPOCHS}\")\n",
        "\n",
        "        for step, (enc_A, enc_P, enc_N, num_mut_tensor) in enumerate(progress_bar):\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # 1. Anchor, Positive, Negative 임베딩 추출 (Pooling은 모델 내부에서 처리)\n",
        "            # [B, 2*H]\n",
        "            emb_A = model(enc_A[\"input_ids\"].to(device), enc_A[\"attention_mask\"].to(device))\n",
        "            emb_P = model(enc_P[\"input_ids\"].to(device), enc_P[\"attention_mask\"].to(device))\n",
        "            emb_N = model(enc_N[\"input_ids\"].to(device), enc_N[\"attention_mask\"].to(device))\n",
        "\n",
        "            # 2. 코사인 거리 계산\n",
        "            dist_AP = cosine_distance(emb_A, emb_P) # Anchor-Positive 거리 (작아야 함) [B]\n",
        "            dist_AN = cosine_distance(emb_A, emb_N) # Anchor-Negative 거리 (커야 함) [B]\n",
        "\n",
        "            # 3. Triplet Margin Loss 적용\n",
        "            # Triplet Loss: max(0, dist(A, P) - dist(A, N) + margin)\n",
        "            # 우리는 dist(A, P) < dist(A, N)을 원하므로, dist(A, P) - dist(A, N)이 음수여야 함\n",
        "\n",
        "            # 동적 마진 대신 고정 마진 사용 (안정성 확보)\n",
        "            loss_triplet = F.relu(dist_AP - dist_AN + dynamic_margin)\n",
        "            loss = loss_triplet.mean()\n",
        "\n",
        "            loss.backward()\n",
        "\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            progress_bar.set_postfix({\"loss\": f\"{loss.item():.4f}\"})\n",
        "\n",
        "        print(f\"[Epoch {epoch+1}] mean loss = {epoch_loss / len(dataloader):.4f}\")\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "KGA_WH0R1if6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# 5. test.csv 전체 임베딩 추출 (추론)\n",
        "# ================================\n",
        "class TestSeqDataset(Dataset):\n",
        "    def __init__(self, df: pd.DataFrame):\n",
        "        self.ids = df[\"ID\"].tolist()\n",
        "        self.seqs = df[\"seq\"].astype(str).tolist()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.ids[idx], self.seqs[idx]\n",
        "\n",
        "\n",
        "def collate_test(batch, tokenizer, max_len: int):\n",
        "    ids = [b[0] for b in batch]\n",
        "    seqs = [b[1] for b in batch]\n",
        "    enc = tokenizer(\n",
        "        seqs,\n",
        "        padding=True,\n",
        "        truncation=True,\n",
        "        max_length=max_len,\n",
        "        return_tensors=\"pt\",\n",
        "    )\n",
        "    return ids, enc\n",
        "\n",
        "\n",
        "def extract_embeddings(\n",
        "    model: VariantSensitiveGLM,\n",
        "    tokenizer: AutoTokenizer,\n",
        "    test_df: pd.DataFrame,\n",
        "    device: torch.device,\n",
        ") -> pd.DataFrame:\n",
        "    model.eval()\n",
        "    dataset = TestSeqDataset(test_df)\n",
        "    dataloader = DataLoader(\n",
        "        dataset,\n",
        "        batch_size=BATCH_SIZE * 4, # 추론 시 배치 사이즈 증대\n",
        "        shuffle=False,\n",
        "        collate_fn=lambda batch: collate_test(batch, tokenizer, MAX_SEQ_LEN),\n",
        "    )\n",
        "\n",
        "    all_ids = []\n",
        "    all_embs = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for ids, enc in tqdm(dataloader, desc=\"Extracting embeddings\"):\n",
        "            input_ids = enc[\"input_ids\"].to(device)\n",
        "            attn_mask = enc[\"attention_mask\"].to(device)\n",
        "\n",
        "            # 모델의 forward 함수는 이미 Concatenative Pooling된 [B, 2*H] 임베딩을 반환\n",
        "            emb = model(input_ids, attn_mask)\n",
        "\n",
        "            emb = emb.detach().cpu().numpy()\n",
        "            all_ids.extend(ids)\n",
        "            all_embs.append(emb)\n",
        "\n",
        "    all_embs = np.vstack(all_embs)  # [N, EMBED_DIM]\n",
        "\n",
        "    # submission 포맷으로 변환\n",
        "    sub = pd.read_csv(SAMPLE_SUB_PATH)\n",
        "\n",
        "    # 임베딩 차원이 1024차원일 경우, sample_submission의 768차원에 맞춰야 하므로 잘라내야 함.\n",
        "    # 하지만, 대회 규정상 2048차원까지 허용되므로 1024차원 그대로 사용하고 submission 파일을 새로 생성하는 것이 원칙.\n",
        "    # 현재 sample_submission은 768차원이므로, 1024차원을 사용하려면 submission 컬럼을 수정해야 합니다.\n",
        "    # 여기서는 1024차원 그대로 출력하며, 제출 시에는 1024차원으로 컬럼을 맞춰서 제출해야 합니다.\n",
        "\n",
        "    # ID 순서에 맞춰서 정렬\n",
        "    id_to_index = {id_: i for i, id_ in enumerate(all_ids)}\n",
        "    ordered_embs = np.zeros((len(test_df), EMBED_DIM), dtype=np.float32)\n",
        "\n",
        "    for i, id_ in enumerate(test_df[\"ID\"].tolist()): # test_df 순서로 정렬\n",
        "        idx = id_to_index[id_]\n",
        "        ordered_embs[i] = all_embs[idx]\n",
        "\n",
        "    emb_cols = [f\"emb_{i:04d}\" for i in range(EMBED_DIM)]\n",
        "    emb_df = pd.DataFrame(ordered_embs, columns=emb_cols)\n",
        "    out_df = pd.concat([test_df[[\"ID\"]], emb_df], axis=1) # ID와 임베딩 결합\n",
        "\n",
        "    return out_df\n",
        "\n",
        "# ================================\n",
        "# 6. 메인 실행부\n",
        "# ================================\n",
        "def main():\n",
        "    set_seed(SEED)\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Device: {device}\")\n",
        "    print(f\"Final Embedding Dimension: {EMBED_DIM}\")\n",
        "\n",
        "    # 1. 데이터 로드\n",
        "    test_df = pd.read_csv(TEST_PATH)\n",
        "    print(\"test shape:\", test_df.shape)\n",
        "\n",
        "    # 2. gLM 로드\n",
        "    tokenizer, model = load_glm_model(MODEL_NAME, device)\n",
        "\n",
        "    # 3. ---------- 파인튜닝 (Self-Supervised Contrastive) ----------\n",
        "    if DO_TRAIN:\n",
        "        # 학습에 사용할 시퀀스 준비\n",
        "        uniq_seqs = test_df[\"seq\"].astype(str).unique().tolist()\n",
        "        random.shuffle(uniq_seqs)\n",
        "        train_seqs = uniq_seqs[:MAX_TRAIN_SEQS] if len(uniq_seqs) > MAX_TRAIN_SEQS else uniq_seqs\n",
        "\n",
        "        print(f\"Train sequences (randomly selected from test.csv): {len(train_seqs)}\")\n",
        "        model = train_variant_sensitive_glm(\n",
        "            model=model,\n",
        "            tokenizer=tokenizer,\n",
        "            train_seqs=train_seqs,\n",
        "            device=device,\n",
        "        )\n",
        "\n",
        "    # 4. ---------- 임베딩 추출 ----------\n",
        "    submission_df = extract_embeddings(\n",
        "        model=model,\n",
        "        tokenizer=tokenizer,\n",
        "        test_df=test_df,\n",
        "        device=device,\n",
        "    )\n",
        "\n",
        "    # 5. 저장\n",
        "    submission_df.to_csv(OUTPUT_PATH, index=False)\n",
        "    print(\"Saved submission to:\", OUTPUT_PATH)\n",
        "    print(\"\\n--- Final Submission Head ---\")\n",
        "    print(submission_df.head())\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 967,
          "referenced_widgets": [
            "fbde6174c6ab46c985d8f565df59c82f",
            "f8a04e92815944ebb662be23c3a3a6de",
            "48c19b8b18524be186e45ba91e57d2b6",
            "d99356ec23604959a57f1e53707bbecc",
            "a7a499c7913d48f0a96ad9b3f31f42f7",
            "3421899a7edc4682b22960d7b2b420b2",
            "d84e2171176a4c889d231a8961d8b819",
            "e7cf25cf124f4fe8b04a1ce6a548c850",
            "dd93ab3a015349a5ac0e800d0cfa174c",
            "524bdfa9cbe14b5b9a6e4b7682d43d63",
            "6b327a73419a4c8f886c5545634b0b23",
            "b4d90e27214947fbad221df49dd40d27",
            "26262d82a1734b68b81e070d26dd88f8",
            "ca31a04838f64178b2b02381eee1f1ff",
            "11c26ff8d3164e6bb22193d3b1245911",
            "1924a1aba25241078941c584de207526",
            "ac68e748b83b4ec19484e86dccea93f7",
            "057f56c1efdc4cf59200f2ddb0be03de",
            "a69041ee7c0747c7a962dd5d6f27bb16",
            "a73116b7806042d19b6209fa1c9c0ca2",
            "06638fdf8033475ea1a8035b3a8789af",
            "30c1bd79a4c245d980f7ca10750e6a0f"
          ]
        },
        "id": "463S_8bH1meG",
        "outputId": "eea36b14-75f0-4758-9df1-bb528555100e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n",
            "Final Embedding Dimension: 1024\n",
            "test shape: (13711, 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of EsmModel were not initialized from the model checkpoint at InstaDeepAI/nucleotide-transformer-v2-50m-multi-species and are newly initialized: ['encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.output.dense.bias', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.output.dense.bias', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.output.dense.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.output.dense.bias', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.output.dense.bias', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.output.dense.bias', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.output.dense.bias', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.output.dense.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.output.dense.bias', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.output.dense.bias', 'pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of EsmModel were not initialized from the model checkpoint at InstaDeepAI/nucleotide-transformer-v2-50m-multi-species and are newly initialized because the shapes did not match:\n",
            "- encoder.layer.0.intermediate.dense.weight: found shape torch.Size([4096, 512]) in the checkpoint and torch.Size([2048, 512]) in the model instantiated\n",
            "- encoder.layer.1.intermediate.dense.weight: found shape torch.Size([4096, 512]) in the checkpoint and torch.Size([2048, 512]) in the model instantiated\n",
            "- encoder.layer.10.intermediate.dense.weight: found shape torch.Size([4096, 512]) in the checkpoint and torch.Size([2048, 512]) in the model instantiated\n",
            "- encoder.layer.11.intermediate.dense.weight: found shape torch.Size([4096, 512]) in the checkpoint and torch.Size([2048, 512]) in the model instantiated\n",
            "- encoder.layer.2.intermediate.dense.weight: found shape torch.Size([4096, 512]) in the checkpoint and torch.Size([2048, 512]) in the model instantiated\n",
            "- encoder.layer.3.intermediate.dense.weight: found shape torch.Size([4096, 512]) in the checkpoint and torch.Size([2048, 512]) in the model instantiated\n",
            "- encoder.layer.4.intermediate.dense.weight: found shape torch.Size([4096, 512]) in the checkpoint and torch.Size([2048, 512]) in the model instantiated\n",
            "- encoder.layer.5.intermediate.dense.weight: found shape torch.Size([4096, 512]) in the checkpoint and torch.Size([2048, 512]) in the model instantiated\n",
            "- encoder.layer.6.intermediate.dense.weight: found shape torch.Size([4096, 512]) in the checkpoint and torch.Size([2048, 512]) in the model instantiated\n",
            "- encoder.layer.7.intermediate.dense.weight: found shape torch.Size([4096, 512]) in the checkpoint and torch.Size([2048, 512]) in the model instantiated\n",
            "- encoder.layer.8.intermediate.dense.weight: found shape torch.Size([4096, 512]) in the checkpoint and torch.Size([2048, 512]) in the model instantiated\n",
            "- encoder.layer.9.intermediate.dense.weight: found shape torch.Size([4096, 512]) in the checkpoint and torch.Size([2048, 512]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train sequences (randomly selected from test.csv): 13711\n",
            "Triplet Loss Margin: 0.2080\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch 1/1:   0%|          | 0/1714 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fbde6174c6ab46c985d8f565df59c82f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 1] mean loss = 0.1646\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Extracting embeddings:   0%|          | 0/429 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b4d90e27214947fbad221df49dd40d27"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved submission to: submission_ntv2_boosted_contrastive.csv\n",
            "\n",
            "--- Final Submission Head ---\n",
            "            ID  emb_0000  emb_0001  emb_0002  emb_0003  emb_0004  emb_0005  \\\n",
            "0  TEST_000000 -1.655428  0.013831  0.865508 -0.918311  0.052765  0.464090   \n",
            "1  TEST_000001  0.136888  0.475598 -0.155153 -0.598040  1.100501  0.013453   \n",
            "2  TEST_000002 -0.767427 -0.067005  0.392438 -0.826294  1.395029 -0.028359   \n",
            "3  TEST_000003  0.877122  0.195837 -0.759369  0.170704 -0.235813  0.337687   \n",
            "4  TEST_000004 -1.185780 -0.695641 -0.033980 -1.010404 -0.552789 -0.045639   \n",
            "\n",
            "   emb_0006  emb_0007  emb_0008  ...  emb_1014  emb_1015  emb_1016  emb_1017  \\\n",
            "0  0.202034  0.604572 -1.006131  ...  0.395031 -0.450418  0.206423  0.715348   \n",
            "1 -0.505302  0.812696 -0.676294  ... -0.174828 -0.475667  0.503319  0.863121   \n",
            "2 -0.618389  1.069441 -1.302056  ...  0.388670 -0.910601  0.411169  0.892094   \n",
            "3 -0.148771  0.692563 -0.118860  ...  0.615766  0.861263  0.070031  0.233345   \n",
            "4  1.093248  0.117325 -0.514936  ...  0.121130  0.133937  0.373447  0.647013   \n",
            "\n",
            "   emb_1018  emb_1019  emb_1020  emb_1021  emb_1022  emb_1023  \n",
            "0  0.292919  0.223283  0.595105  0.137900  1.320136  0.066206  \n",
            "1  0.248535  1.040422  0.185918 -0.283208  0.807370  0.710408  \n",
            "2  0.146311  1.076876  0.467372 -0.066379  1.243386  0.333882  \n",
            "3 -0.057717  0.385201 -0.759398  0.059146  0.353173  0.641343  \n",
            "4  0.225984  0.676940  0.316576  0.090842  0.680215 -0.437202  \n",
            "\n",
            "[5 rows x 1025 columns]\n"
          ]
        }
      ]
    }
  ]
}